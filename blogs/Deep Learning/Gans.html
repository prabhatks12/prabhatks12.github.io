<head>
	<title>Generative Adverserial Network</title>

	<link rel="icon" href="../../images/newlogo.png">
	<script src="../../script/script.js"></script>
	<link rel="stylesheet" type="text/css" href="deepLearningStyle.css">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">

</head>

<body>

	<br><br>
	<div style="text-align: center;">
		<h2> Generative Adverserial Network </h2>
	</div>

	<br><br>
	<div style="text-align: left;">

		<!-- 
		*************************************************************************
		*	1. How much should i know?   
		*************************************************************************
		-->

		<h3> How much should i know? </h3>

		<ul>			
			<li>A Friendly Introduction to GAN (link in resources)</li>
			<li>Conditional Gan : 
				<a href="https://arxiv.org/pdf/1411.1784.pdf">Paper</a> |  
				<a href="https://www.youtube.com/watch?v=7Tlk3Gql-Wg&ab_channel=AhladKumar">Explanation</a> |   
				<a href="https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/">Working Code</a>
			</li>
			<li>Cycle Gan: type of image to image</li> https://www.youtube.com/watch?v=m47qsfSZoTI&ab_channel=UCFCRCV
			<li>Pixel 2 pixel Gan : edges to images, eg: drawing to real world image</li> https://arxiv.org/pdf/1611.07004.pdf
			<li>StyleGan : domain transfer, eg: normal person image to cartoon</li>
			Conditional gan, using class as input to both dic and gen
		</ul>

			
		<br><br>
		
		<!-- 
		*************************************************************************
		*	2. INTRODUCTION   
		*************************************************************************
		-->

		<h4> Introduction : </h4><br>

		<b>Side Information</b> <br>

		<ol>
			<li> Framework designed by Ian GoodFellow and team, 2014. </li>

			<li> Proposed as a type of unsupervised learning, with a goal to generate new samples form the same distribution. </li>

			<li> Now, it can be used for supervised, semi-supervised and reinforcement learning also. </li>
		</ol>

		<br><b>Main Idea</b> <br>

		<ol>
			<li> Two types of neural network model, Generator and Discriminator participates in <u>zero sum contest</u>, where loss of one model is gain of other </li>

			<li> Generator learns from latent space ( <u>latent variables are those which are derived from other variables, they are not observed directly </u>) and map it to statifiable distribution. Whereas, discriminator learns directly from the dataset or true data distribution(discriminators are typically classifiers). </li>

			<li> Weights in both of the models are updated dyanamically using backpropagation </li>

			<li> Model is trained until generator fools discriminator half of the time. </li>
		</ol>

		Read more : <a href="https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/">A Gentle Introduction to GAN </a> |  <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network"> Generative adversarial network </a> | <a href="https://en.wikipedia.org/wiki/Generative_model"> Generative model
		</a><br>

		<br><br>

		
		<!-- 
		*************************************************************************
		*
		*	3. TYPES OF GANS
		*   
		*************************************************************************
		-->

		<h4>Types</h4> <br>

		<h5>1. Normal GANs </h5>  
		


		<h5>2. Conditional GANs </h5>

		<a href="https://arxiv.org/pdf/1411.1784.pdf">Paper</a> |  
		<a href="https://www.youtube.com/watch?v=7Tlk3Gql-Wg&ab_channel=AhladKumar">Explanation</a> |   
		<a href="https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/">Working Code</a>
		
		<br><br>

		<b>From the paper :</b><br>

		<ul>
			<li>Preivosuly the GANs where producing the combined results for all categories, conditional GANs 
			made it possible to generate results for a specific category. </li>

			<li>We have to pass Y to both the generator and discriminator. According to the paper, "y could be any kind of auxiliary information, such as class labels or data from other modalities". Here's an image from the paper.</li>

			<img src="Images/GANs_conditional.png" width = 60% height = 80%> <br><br>

			<li> The loss function is also changed, <br>				
				<b>Normal GANs:</b> min(G)max(D) V(D, G) = E<sub>x∼p<sub>data</sub>(x)</sub>[log D(x)] + E<sub>z∼p<sub>z</sub>(z)</sub>[log(1 − D(G(z)))] <br><br>
				<b>Conditional GANs:</b>  min(G)max(D) V(D, G) = E<sub>x∼p<sub>data</sub>(x)</sub>[log D(x|y)] + E<sub>z∼p<sub>z</sub>(z)</sub>[log(1 − D(G(z|y)))]
			</li>
		</ul>

		<br>
		<b>From the explanation :</b><br><br>

		Explanation is similar to the paper with code example. Also see this explanation of High Resolution Image Synthesis which uses Conditional Gans and boundaries of images to create good resolution image. <br><br>

		<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ZjWy0bCrDnw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

		<br>
		Its's paper : <a href="https://arxiv.org/pdf/1711.11585.pdf">High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs </a> <br><br>

		<br>
		<b>Code: </b> <br><br>

		See Machine Learning Mastery, the whole code for both GANs and Conditional GANs. Try to relate the above image with model description. Link: <a href="https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/">How to Develop a Conditional GAN (cGAN) From Scratch</a><br><br>		
		
		<hr>


		
		Fully Visible Belief Nets: search for equation
		pixlecnn is faster than pixelrnn. Generation time is still slow, training time is faster.

		See how to improve pixelcnn performance like gated convolutional layers, short-cut connections

		Variational Auto-Encoder : 

		latent

		encoder , features, decoder, loss function
		We don't have labels
		
		https://www.tensorflow.org/tutorials/generative/dcgan

		</p>

		<br><br>

		<!-- 
		*************************************************************************
		*	4. MATHS BEHIND IT   
		*************************************************************************
		-->

		<h4>Maths behind it </h4><br>

		<br><br>
		<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/J1aG12dLo4I" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

		<br><br>
		<iframe src="https://www.youtube-nocookie.com/embed/Gib_kiXgnvA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

		<br><br>
		<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/8L11aMN5KY8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


		<br><br><br><b>Discriminator</b> <br>
		<img src="Images/discriminator_math.png">

		<br><br><br><b>Generator</b> <br>
		<img src="Images/generator_math.png">

		<br><br><br>
		Read more : <a href="https://github.com/prabhatks12/Maths_Behind_Gans/blob/master/GANs_in_Slanted_Land.ipynb"> Working Example </a>

		
		<!-- 
		*************************************************************************
		*	5. FULL LECTURES   
		*************************************************************************
		-->

		<br><br>
		<h4>Lectures </h4><br>
		
		<br><br>

		<h5>Deep Generative Modeling | MIT </h5> <br><br>
		<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/rZufA635dq4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

		<br><br>
		<b>Imp Content</b> <br>

		<b>Auto Encoders (or Traditional AutoEncoders): </b>

		It uses bottleneck approach, like compressing, ensuring that model leanrs to compress image into smaller latent space. It a diterministic approach. <br><br>

		<u>Encoder</u> : Mapping a given data sample to a lower dimension latent space 'z', basically compressing it <br>
		<u>Decoder</u> : Reconstruct the data sample from the latent space 'z', decompressing it. <br><br>

		But using the Neural nets for this. Challenge: Clearity is being lost as many pixel info are lost due to cnn layers like dropouts. Fully unsupervised as we are not having any label. 2D means using 2 variables to describe an image. <br><br>

		<b>Varitional Auto Encoders: </b> <br>
		Instead of using bottleneck approach to lower the latent space, learn the probabilty distribution using mean and standard deviation , we can create a probabilistic ditribution of latent space. <br>
		<br>
		<u>Encoder</u> : p(Z|X) : Finding probability distribution of latent space Z, given data sample X <br>
		<u>Decoder</u>: q(X|Z) : Given the latent space Z, finding probability distribution of sample X  <br>

		<u>Loss</u>: Reconstruction loss + Regularization loss (Uses prior prob , so that network try to learn this prior distribution. Can use Gaussian for this, mean of 0, std = 1. Network may overfit without it) <br><br>


		<p class="seeifimp">See, how KL divergence can be used for Regularization loss </p>

		<b>Reparameterizing the sample layer: </b>

		What I understood, we were unable to backpropagate due to stochastic node, so we took out the part which was causing the issue by re parameterizing or expanding that node z <br>
		
		<p class="doubt"> Topic still not clear, see if imp </p>

		Rest: How gan works by taking a linear exmple. 


		<br><br>
		<hr>
		<h5> Lecture 13 | Generative Models</h5> <br><br>
		<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/5WoItGTWV54" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

		Important Content:
		<b>SuperResolution </b> : Will be required after generating images from GANs to increase the resolution. See how to implement : <a href="https://www.pyimagesearch.com/2020/11/09/opencv-super-resolution-with-deep-learning/"> PyImageSerch </a> <a href="https://keras.io/examples/vision/super_resolution_sub_pixel/"> Keras IO </a> 


		<b>Taxonomy of Generative models</b><br>
		
		Explicit  density estimation : <br>
		
		<ol>
		<li> Tractable density : Fully Visible Belief Nets: NADE, MADE, PixelRNN/CNN <br>
		</li>
		
		<li> Approximate density 
			<ul>
			<li> Variational : Variational auto encoder</li>
			<li> Markov chain : Boltzmann machine </li>
			</ul>
		</li>
		</ol>

		<b>Implicit density estimation: </b>
		
		<ol>
			<li> Direct : GAN </li>
			<li> Markov Chain : GSN </li>
		</ol>
		
		<br>
		To improve the image quality, super resolution and colurization. 


		Pixel RNN: See how based on previous modeled pixels, we can model new one. Modelling every adjacent pixels one by one.

		Pixel CNN:  


		<br><br>
		<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/wFsI2WqUfdA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


	</div>

	<br><br>

	<div style="text-align: left;">
		<h3> References </h3>
		<br>
		<ul>
			
			<b>Explanation : </b> <br><br>

			<li> Youtube : <a href="https://youtu.be/CIfsB_EYsVI">Adversarial Examples and Adversarial Training</a> </li>
			
			<li> Youtube : <a href="https://youtu.be/5WoItGTWV54">Lecture 13 | Generative Models</a> </li>
			
			<li> Youtube : <a href="https://youtu.be/8L11aMN5KY8">A Friendly Introduction to Generative Adversarial Networks</a> </li>

			<li> Youtube: <a href="https://youtu.be/eyxmSmjmNS0"> Generative Adversarial Networks (Paper Explained)</a></li>
			
			<li> Machine learning mastery : <a href="https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/">A Gentle Introduction to Generative Adversarial Networks </a> </li>
			

			<br><br>
			
			<b>Practical (Machine learning mastery) : </b> <br><br>

			<li> <a href="https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/">Pix2Pix GAN for Image-to-Image Translation </a> </li>
			
			<li> <a href="https://machinelearningmastery.com/cyclegan-tutorial-with-keras/">CycleGAN for Image-to-Image Translation with Keras </a> </li>
			
			<li> <a href="https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/">1D Generative Adversarial Network From Scratch in Keras </a> </li>
			
			<li> <a href="https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/">How to Develop a Conditional GAN (cGAN) From Scratch</a></li>
			
			<li> <a href="https://machinelearningmastery.comhow-to-train-a-progressive-growing-gan-in-keras-for-synthesizing-faces/">Progressive Growing GAN in Keras for Synthesizing Faces</a></li>
			
			<li> <a href="https://machinelearningmastery.com/category/generative-adversarial-networks/"> All topics Gans </a></li>

			<br><br>

			Papers :

			<a href="https://arxiv.org/pdf/1601.06759.pdf">Pixel Recurrent Neural Networks</a> <a href="youtube.com/watch?v=-FFveGrG46w&ab_channel=UCFCRCV">Explanation Youtube</a>
			<a href="https://arxiv.org/pdf/1606.05328.pdf">Conditional Image Generation with PixelCNN Decoders</a>
			<a href="https://arxiv.org/pdf/1706.00531.pdf">PixelGAN Autoencoders</a>
			<a href="https://arxiv.org/pdf/1805.09987.pdf">Learning from Multi-domain Artistic Images for Arbitrary Style Transfer</a>

			Blogs

			<a href="https://www.analyticsvidhya.com/blog/2020/01/generative-models-gans-computer-vision/">What are Generative Models and GANs? The Magic of Computer Vision</a>
			<a href="https://towardsdatascience.com/auto-regressive-generative-models-pixelrnn-pixelcnn-32d192911173">Auto-Regressive Generative Models (PixelRNN, PixelCNN++)</a>

			
			<b>Other great links : </b> <br><br>

			<li> Free code camp: <a href="https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/">An intuitive introduction to Generative Adversarial Networks (GANs)</a></li>

			<li> Real python: <a href="https://realpython.com/generative-adversarial-networks/">Generative Adversarial Networks: Build Your First Models </a></li> 



			https://www.youtube.com/watch?v=r3L3JT_TLTM&ab_channel=Crazymuse

			https://www.youtube.com/watch?v=Nrsy6vF7rSw&ab_channel=JeffHeaton

			https://www.youtube.com/watch?v=qEN-v6JyNJI&ab_channel=JeffHeaton

			https://www.youtube.com/watch?v=dCKbRCUyop8&ab_channel=ArxivInsights

			https://www.youtube.com/watch?v=nB8uVGbesZ4&ab_channel=AhladKumar


			extra
			<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/9zKuYvjFFS8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

			<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/JgvyzIkgxF0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

		</ul>
	</div>

	todo: Reference every image and video, rmit style

</body>


